{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The following was requested:\n",
    "\n",
    "1. We take the same original picture for all attempts.\n",
    "2. We take the same \"noisy picture\" for all attempts - and we give it MSE and SSIM score.\n",
    "3. We denoise with original \"float\" - give MSE and SSIM.\n",
    "4. We denoise with all types of quantization that you tried and give MSE and SSIM.\n",
    "5. Please give a conclusion in the end - if some types of quantization are better than others.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import os\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from data import NoisyBSDSDataset\n",
    "from argument import Args\n",
    "from model import DnCNN, UDnCNN, DUDnCNN, QDUDnCNN\n",
    "import nntools as nt\n",
    "#from utils import DenoisingStatsManager, plot, NoisyBSDSDataset\n",
    "import utils\n",
    "import utils2\n",
    "from skimage import metrics\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "import torch.utils.data as td\n",
    "import torch.quantization.quantize_fx as quantize_fx\n",
    "from torch.quantization.fuse_modules import fuse_known_modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import model\n",
    "import inference\n",
    "from prettytable import PrettyTable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def main(img_set,model_path,qat=False,quantize='none'):\n",
    "    args = Args()\n",
    "    args.quantize = quantize\n",
    "    device = 'cpu'\n",
    "    if qat:\n",
    "        denoise, qat_state = inference.load_model(model_path, QDUDnCNN, args.D, args.C, device=device)\n",
    "    else:\n",
    "        denoise, qat_state = inference.load_model(model_path, DUDnCNN, args.D, args.C, device=device)\n",
    "\n",
    "    img = []\n",
    "    titles = ['clean', 'noise', 'denoise']\n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    if args.quantize:\n",
    "        print('Quantize model...'+quantize)\n",
    "        denoise = utils2.quantize_model(args.quantize, denoise, input_example=x, qat_state=qat_state)\n",
    "\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        y = denoise(x)\n",
    "    img.append(y[0])\n",
    "\n",
    "    print(f'Elapsed: {(time.time() - t) * 1000:.2f}ms')\n",
    "    print(f'Image size is {x[0].shape}.')\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    y3 = utils2.myimret(img[2])\n",
    "    utils2.compare_images(y1,y3)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(9,5), sharex='all', sharey='all')\n",
    "    for i in range(len(img)):\n",
    "        utils2.myimshow(img[i], ax=axes[i])\n",
    "        axes[i].set_title(f'{titles[i]}')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def eval_origin(img_set,display=False): \n",
    "    device = 'cpu'\n",
    "    \n",
    "    img = []\n",
    "    x, clean = img_set\n",
    "#    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "    img.append(clean)\n",
    "#    img.append(x[0])\n",
    "    img.append(x)\n",
    "\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    mse,ssim = utils2.compare_images(y1,y1,display)\n",
    "    return mse, ssim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def eval_noisy(img_set,display=False): \n",
    "    device = 'cpu'\n",
    "    \n",
    "    img = []\n",
    "    x, clean = img_set\n",
    "#    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "    img.append(clean)\n",
    "#    img.append(x[0])\n",
    "    img.append(x)\n",
    "\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    mse,ssim = utils2.compare_images(y1,y2,display)\n",
    "    return mse, ssim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def eval_image_set(img_set,model_path,qat=False,quantize='none',display=False,print_out=False): \n",
    "    args = Args()\n",
    "    args.quantize = quantize\n",
    "    device = 'cpu'\n",
    "    if qat:\n",
    "        denoise, qat_state = inference.load_model(model_path, QDUDnCNN, args.D, args.C, device=device)\n",
    "    else:\n",
    "        denoise, qat_state = inference.load_model(model_path, DUDnCNN, args.D, args.C, device=device)\n",
    "    \n",
    "    img = []\n",
    "    titles = ['clean', 'noise', 'denoise'] \n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    if args.quantize:\n",
    "        denoise = utils2.quantize_model(args.quantize, denoise, input_example=x, qat_state=qat_state)\n",
    "\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        y = denoise(x) \n",
    "    t_elapsed = (time.time() - t)*1000\n",
    "    img.append(y[0])\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    y3 = utils2.myimret(img[2])\n",
    "    mse0, ssim0 = utils2.compare_images(y1,y2,print_out)\n",
    "    mse, ssim = utils2.compare_images(y1,y3,print_out)\n",
    "\n",
    "    if display:\n",
    "        fig, axes = plt.subplots(ncols=3, figsize=(9,5), sharex='all', sharey='all')\n",
    "        for i in range(len(img)):\n",
    "            utils2.myimshow(img[i], ax=axes[i])\n",
    "            axes[i].set_title(f'{titles[i]}') \n",
    "    return t_elapsed, quantize, mse, ssim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def experiment(img,display=True):\n",
    "    img_set = img\n",
    "\n",
    "    t = PrettyTable(['training','quantization','time','mse','ssim'])\n",
    "    t.float_format=\".5\"\n",
    "    t.float_format['time'] = \".2\"\n",
    "    t.border=True\n",
    "    t.align=\"l\"\n",
    "    t.align[\"mean time\"]=\"r\"\n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/no_qat/checkpoint.pth' \n",
    "    mse_origin,ssim_origin = eval_origin(img_set, False)\n",
    "    mse_noisy, ssim_noisy = eval_noisy(img_set, False)\n",
    "    t.add_row(['NA (origin)',\"NA\",\"NA\",mse_origin,ssim_origin])\n",
    "    t.add_row(['NA (noisy)',\"NA\",\"NA\",mse_noisy,ssim_noisy])\n",
    "\n",
    "    eval_time_none,q, mse, ssim = eval_image_set(img_set, path, False,'none', display) \n",
    "    t.add_row(['standard',q,(eval_time_none/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'fx_static', False) \n",
    "    t.add_row(['standard',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'fx_dynamic', False) \n",
    "    t.add_row(['standard',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/qat/checkpoint.pth' \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "    t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "    t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_dynamic', False) \n",
    "    t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    path = os.environ.get('TRAINING_DIR')+'/qat_fx_static/checkpoint.pth' \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "    t.add_row(['QAT_fc_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "    t.add_row(['QAT_fc_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_dynamic', False) \n",
    "    t.add_row(['QAT_fc_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    print(t)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def experiment_mean(img,cycles,display=True,mean_only=False):\n",
    "    img_set = img\n",
    "    \n",
    "    cs = cycles\n",
    "    rows = 6\n",
    "    time_array = np.zeros((rows,cycles),dtype = np.float32)\n",
    "    mse_array = np.zeros((rows,cycles),dtype = np.float32)\n",
    "    ssim_array = np.zeros((rows,cycles),dtype = np.float32)\n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/no_qat/checkpoint.pth' \n",
    "    eval_image_set(img_set, path, False,'none', True) \n",
    "\n",
    "\n",
    "    for i in range(cs):\n",
    "        if (mean_only == False):\n",
    "            print(\"==> experiment %2d\" %i)\n",
    "        t = PrettyTable(['training','quantization','time','mse','ssim'])\n",
    "        t.float_format=\".5\"\n",
    "        t.float_format['time'] = \".2\"\n",
    "        t.border=True\n",
    "        t.align=\"l\"\n",
    "        t.align[\"mean time\"]=\"r\"\n",
    "        \n",
    "        path = os.environ.get('TRAINING_DIR')+'/no_qat/checkpoint.pth' \n",
    "        mse_origin,ssim_origin = eval_origin(img_set, False)\n",
    "        mse_noisy, ssim_noisy = eval_noisy(img_set, False)\n",
    "        t.add_row(['NA (origin)',\"NA\",\"NA\",mse_origin,ssim_origin])\n",
    "        t.add_row(['NA (noisy)',\"NA\",\"NA\",mse_noisy,ssim_noisy])\n",
    "\n",
    "        eval_time_none,q, mse, ssim = eval_image_set(img_set, path, False,'none', display) \n",
    "        time_array[0,i] = (eval_time_none/eval_time_none)*100\n",
    "        mse_array[0,i] = mse\n",
    "        ssim_array[0,i] = ssim\n",
    "        t.add_row(['standard',q,(eval_time_none/eval_time_none)*100,mse,ssim])\n",
    "\n",
    "        eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'fx_static', False) \n",
    "        time_array[1,i] = (eval_time/eval_time_none)*100\n",
    "        mse_array[1,i] = mse\n",
    "        ssim_array[1,i] = ssim\n",
    "        t.add_row(['standard',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "\n",
    "        path = os.environ.get('TRAINING_DIR')+'/qat/checkpoint.pth' \n",
    "        eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "        time_array[2,i] = (eval_time/eval_time_none)*100\n",
    "        mse_array[2,i] = mse\n",
    "        ssim_array[2,i] = ssim\n",
    "        t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    \n",
    "        eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "        time_array[3,i] = (eval_time/eval_time_none)*100    \n",
    "        mse_array[3,i] = mse\n",
    "        ssim_array[3,i] = ssim\n",
    "        t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "        \n",
    "        path = os.environ.get('TRAINING_DIR')+'/qat_fx_static/checkpoint.pth' \n",
    "        eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False)\n",
    "        time_array[4,i] = (eval_time/eval_time_none)*100\n",
    "        mse_array[4,i] = mse\n",
    "        ssim_array[4,i] = ssim\n",
    "        t.add_row(['QAT_fx_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "        \n",
    "        eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "        time_array[5,i] = (eval_time/eval_time_none)*100\n",
    "        mse_array[5,i] = mse\n",
    "        ssim_array[5,i] = ssim\n",
    "        t.add_row(['QAT_fx_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "\n",
    "        if (mean_only == False):    \n",
    "            print(t)\n",
    "    \n",
    "    print(\"Summary of experiments\")\n",
    "    \n",
    "    pt = PrettyTable(['training','quantization','mean time','mean mse','mean ssim'])\n",
    "    pt.float_format = \".5\"\n",
    "    pt.float_format['mean time'] = \".2\"\n",
    "    pt.border=True\n",
    "    pt.align=\"l\"\n",
    "    pt.align[\"mean time\"]=\"r\"\n",
    "    \n",
    "    pt.add_row(['standard','none',np.mean(time_array[0,:]),np.mean(mse_array[0,:]),np.mean(ssim_array[0,:])])\n",
    "    pt.add_row(['standard','static',np.mean(time_array[1,:]),np.mean(mse_array[1,:]),np.mean(ssim_array[1,:])])\n",
    "    pt.add_row(['QAT','none',np.mean(time_array[2,:]),np.mean(mse_array[2,:]),np.mean(ssim_array[2,:])])    \n",
    "    pt.add_row(['QAT','static',np.mean(time_array[3,:]),np.mean(mse_array[3,:]),np.mean(ssim_array[3,:])])\n",
    "    pt.add_row(['QAT_fx_static','none',np.mean(time_array[4,:]),np.mean(mse_array[4,:]),np.mean(ssim_array[4,:])])\n",
    "    pt.add_row(['QAT_fx_static','static',np.mean(time_array[5,:]),np.mean(mse_array[5,:]),np.mean(ssim_array[5,:])])\n",
    "    print(pt)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_root_dir = os.environ.get('DATA_DIR')+'/images'\n",
    "test_set = NoisyBSDSDataset(dataset_root_dir, mode='test', image_size=(320, 320))\n",
    "img_set = test_set[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Image Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment_mean(img_set,10,False, True)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ten Images Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = 10\n",
    "for i in range(x):\n",
    "    img_set = test_set[i]\n",
    "    print((\"Experiment {}\").format(i))\n",
    "    experiment_mean(img_set,10,False, True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summmary\n",
    "\n",
    "The experiment clearly showed the significant processing time improvement without much of the quality degradation using all variants of static quantization. Suprisingly, Quantization Aware Training did not produce superior results over fx_static method, and in some cases the quality were reduced. It is possible that QAT will depend on the type of the data and with different dataset or algorithm will produce significantly better results. That assumption needs to be explored. The field is still very new. The project used PyTorch latest quantization techniques and software, some of which is still in pre-release. PyTorch quantization support only x86 and ARM architecures. x86 backend was used in the project.\n",
    "\n",
    "The testing was done with one original image and and one noisy deriviated image. The time fluctuation between experiments can be attributed to the compute infrastructure and cluster resources. The summary values appeard to be  consistent over multiple experement runs performed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}