{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you, please, summarize your results as follows in a separate section in the end?\n",
    "The data should be as follows:\n",
    "1. We take the same original picture for all attempts.\n",
    "2. We take the same \"noisy picture\" for all attempts - and we give it MSE and SSIM score.\n",
    "3. We denoise with original \"float\" - give MSE and SSIM.\n",
    "4. We denoise with all types of quantization that you tried and give MSE and SSIM.\n",
    "5. Please give a conclusion in the end - if some types of quantization are better than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Display original picture \n",
    "    Give MSI and SSIM score against itself\n",
    "    Display noisy picture\n",
    "    Give MSI and SSIM score between origional and noisy    \n",
    "     _____________________________________________________________________________________\n",
    "    | No Quantization                                          | performance %| MSE| SSIM |\n",
    "    | Static Quantization of standard model - fx_static        | performance %| MSE| SSIM |\n",
    "    | Dynamic Quantization of standard model - fx_dynamic      | performance %| MSE| SSIM |\n",
    "    | Static Quantization of QAT model - fx_static             | performance %| MSE| SSIM |\n",
    "    | Dynamic Quantization of QAT model - fx_dynamic           | performance %| MSE| SSIM |\n",
    "    | Static Quantization of QAT_fx_static model - fx_static   | performance %| MSE| SSIM |\n",
    "    | Dynamic Quantization of QAT_fx_static model - fx_dynamic | performance %| MSE| SSIM |\n",
    "     _____________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from data import NoisyBSDSDataset\n",
    "from argument import Args\n",
    "from model import DnCNN, UDnCNN, DUDnCNN, QDUDnCNN\n",
    "import nntools as nt\n",
    "#from utils import DenoisingStatsManager, plot, NoisyBSDSDataset\n",
    "import utils\n",
    "import utils2\n",
    "from skimage import metrics\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.utils.data as td\n",
    "import torch.quantization.quantize_fx as quantize_fx\n",
    "from torch.quantization.fuse_modules import fuse_known_modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import model\n",
    "import inference\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(img_set,model_path,qat=False,quantize='none'):\n",
    "    args = Args()\n",
    "    args.quantize = quantize\n",
    "    device = 'cpu'\n",
    "    if qat:\n",
    "        denoise, qat_state = inference.load_model(model_path, QDUDnCNN, args.D, args.C, device=device)\n",
    "    else:\n",
    "        denoise, qat_state = inference.load_model(model_path, DUDnCNN, args.D, args.C, device=device)\n",
    "\n",
    "    img = []\n",
    "    titles = ['clean', 'noise', 'denoise']\n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    if args.quantize:\n",
    "        print('Quantize model...'+quantize)\n",
    "        denoise = utils2.quantize_model(args.quantize, denoise, input_example=x, qat_state=qat_state)\n",
    "\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        y = denoise(x)\n",
    "    img.append(y[0])\n",
    "\n",
    "    print(f'Elapsed: {(time.time() - t) * 1000:.2f}ms')\n",
    "    print(f'Image size is {x[0].shape}.')\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    y3 = utils2.myimret(img[2])\n",
    "    utils2.compare_images(y1,y3)\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(9,5), sharex='all', sharey='all')\n",
    "    for i in range(len(img)):\n",
    "        utils2.myimshow(img[i], ax=axes[i])\n",
    "        axes[i].set_title(f'{titles[i]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_q(img_set,model_path,qat=False,quantize='none',display=False): \n",
    "    args = Args()\n",
    "    args.quantize = quantize\n",
    "    device = 'cpu'\n",
    "    if qat:\n",
    "        denoise, qat_state = inference.load_model(model_path, QDUDnCNN, args.D, args.C, device=device)\n",
    "    else:\n",
    "        denoise, qat_state = inference.load_model(model_path, DUDnCNN, args.D, args.C, device=device)\n",
    "    \n",
    "    img = []\n",
    "    titles = ['clean', 'noise', 'denoise'] \n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "#    if display:\n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    if args.quantize:\n",
    "        denoise = utils2.quantize_model(args.quantize, denoise, input_example=x, qat_state=qat_state)\n",
    "\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        y = denoise(x) \n",
    "    img.append(y[0])\n",
    "#    print(f'Elapsed: {(time.time() - t) * 1000:.2f}ms')\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    y3 = utils2.myimret(img[2])\n",
    "    utils2.compare_images(y1, y3)\n",
    "\n",
    "    if display:\n",
    "        fig, axes = plt.subplots(ncols=3, figsize=(9,5), sharex='all', sharey='all')\n",
    "        for i in range(len(img)):\n",
    "            utils2.myimshow(img[i], ax=axes[i])\n",
    "            axes[i].set_title(f'{titles[i]}') \n",
    "    return (time.time() - t) * 1000, quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_origin(img_set,display=False): \n",
    "    device = 'cpu'\n",
    "    \n",
    "    img = []\n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    mse,ssim = utils2.compare_images(y1,y1,False)\n",
    "    return mse, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_noisy(img_set,display=False): \n",
    "    device = 'cpu'\n",
    "    \n",
    "    img = []\n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    mse,ssim = utils2.compare_images(y1,y2,False)\n",
    "    return mse, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_image_set(img_set,model_path,qat=False,quantize='none',display=False): \n",
    "    args = Args()\n",
    "    args.quantize = quantize\n",
    "    device = 'cpu'\n",
    "    if qat:\n",
    "        denoise, qat_state = inference.load_model(model_path, QDUDnCNN, args.D, args.C, device=device)\n",
    "    else:\n",
    "        denoise, qat_state = inference.load_model(model_path, DUDnCNN, args.D, args.C, device=device)\n",
    "    \n",
    "    img = []\n",
    "    titles = ['clean', 'noise', 'denoise'] \n",
    "    x, clean = img_set\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    \n",
    "    img.append(clean)\n",
    "    img.append(x[0])\n",
    "\n",
    "    if args.quantize:\n",
    "        denoise = utils2.quantize_model(args.quantize, denoise, input_example=x, qat_state=qat_state)\n",
    "\n",
    "    t = time.time()\n",
    "    with torch.no_grad():\n",
    "        y = denoise(x) \n",
    "    t_elapsed = (time.time() - t)*1000\n",
    "    img.append(y[0])\n",
    "    y1 = utils2.myimret(img[0])\n",
    "    y2 = utils2.myimret(img[1])\n",
    "    y3 = utils2.myimret(img[2])\n",
    "    mse, ssim = utils2.compare_images(y1,y3)\n",
    "\n",
    "    if display:\n",
    "        fig, axes = plt.subplots(ncols=3, figsize=(9,5), sharex='all', sharey='all')\n",
    "        for i in range(len(img)):\n",
    "            utils2.myimshow(img[i], ax=axes[i])\n",
    "            axes[i].set_title(f'{titles[i]}') \n",
    "    return t_elapsed, quantize, mse, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(img,display=True):\n",
    "    img_set = img\n",
    "\n",
    "    t = PrettyTable(['training','quantization','time','mse','ssim'])\n",
    "    t.float_format=\".5\"\n",
    "    t.float_format['time'] = \".2\"\n",
    "    t.border=True\n",
    "    t.align=\"r\"\n",
    "    t.align[\"quantization\"]=\"l\"\n",
    "    t.align[\"training\"]=\"l\"\n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/no_qat/checkpoint.pth' \n",
    "    mse_origin,ssim_origin = eval_origin(img_set, False)\n",
    "    mse_noisy, ssim_noisy = eval_noisy(img_set, False)\n",
    "    t.add_row(['NA (origin)',\"NA\",\"NA\",mse_origin,ssim_origin])\n",
    "    t.add_row(['NA (noisy)',\"NA\",\"NA\",mse_noisy,ssim_noisy])\n",
    "\n",
    "    eval_time_none,q, mse, ssim = eval_image_set(img_set, path, False,'none', display) \n",
    "    t.add_row(['standard',q,(eval_time_none/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'fx_static', False) \n",
    "    t.add_row(['standard',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'fx_dynamic', False) \n",
    "    t.add_row(['standard',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/qat/checkpoint.pth' \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "    t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "    t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_dynamic', False) \n",
    "    t.add_row(['QAT',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    path = os.environ.get('TRAINING_DIR')+'/qat_fx_static/checkpoint.pth' \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "    t.add_row(['QAT_fc_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "    t.add_row(['QAT_fc_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_dynamic', False) \n",
    "    t.add_row(['QAT_fc_static',q,(eval_time/eval_time_none)*100,mse,ssim])\n",
    "    print(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def experiment_test(img,display=False):\n",
    "    img_set = img\n",
    "\n",
    "    eval_origin(img_set, display)    \n",
    "    eval_origin(img_set, display)\n",
    "    eval_origin(img_set, display)\n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/no_qat/checkpoint.pth' \n",
    "    eval_image_set(img_set, path, False,'none', display) \n",
    "    eval_image_set(img_set, path, False,'fx_static', False) \n",
    "    eval_image_set(img_set, path, False,'fx_dynamic', False) \n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/qat/checkpoint.pth' \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_dynamic', False) \n",
    "\n",
    "    path = os.environ.get('TRAINING_DIR')+'/qat_fx_static/checkpoint.pth' \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, False,'none', False) \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_static', False) \n",
    "    eval_time,q, mse, ssim = eval_image_set(img_set, path, True,'fx_dynamic', False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = os.environ.get('DATA_DIR')+'/images'\n",
    "test_set = utils2.NoisyBSDSDataset(dataset_root_dir, mode='test', image_size=(320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils2.NoisyBSDSDataset"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_test(test_set[1],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test_set[1],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test_set[1],False)\n",
    "experiment(test_set[1],False)\n",
    "experiment(test_set[1],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test_set[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test_set[0],False)\n",
    "experiment(test_set[0],False)\n",
    "experiment(test_set[0],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test_set[99],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(test_set[99],False)\n",
    "experiment(test_set[99],False)\n",
    "experiment(test_set[99],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
